# services/report_service.py
"""
Report generation service - creates Markdown/PDF reports from stored analysis.
"""

import os
import sys
from datetime import datetime
from typing import Optional, Dict, Any

sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from config.settings import get_logger
from data.database import SessionLocal
from data import repository as repo
from data.models import Company, Filing, Section, Summary

logger = get_logger(__name__)


def generate_markdown_report(
    filing_id: int,
    output_dir: str = "reports",
    include_all_paragraphs: bool = False
) -> str:
    """
    Generate a Markdown report for a filing.
    
    Args:
        filing_id: Database ID of the filing
        output_dir: Directory to save the report
        include_all_paragraphs: If True, include all paragraphs (not just top 5)
        
    Returns:
        Path to the generated report file
    """
    db = SessionLocal()
    
    try:
        # Get filing and related data
        filing = repo.get_filing_by_id(db, filing_id)
        if not filing:
            raise ValueError(f"Filing not found: {filing_id}")
        
        company = db.query(Company).filter(Company.id == filing.company_id).first()
        sections = repo.get_sections_by_filing(db, filing_id)
        
        if not sections:
            raise ValueError(f"No sections found for filing: {filing_id}")
        
        # Get Item 1A section
        risk_section = next((s for s in sections if s.section_type == "Item 1A"), None)
        if not risk_section:
            raise ValueError("No Risk Factors section found")
        
        # Get summary if exists
        summary = repo.get_summary_by_filing(db, filing_id, "Item 1A")
        
        # Get top scored paragraphs
        top_scored = repo.get_top_scored_paragraphs(db, risk_section.id, method="embedding", limit=10 if include_all_paragraphs else 5)
        
        # Build report
        ticker = company.ticker if company else "UNKNOWN"
        report_date = datetime.now().strftime("%Y-%m-%d")
        filing_date = filing.filing_date.strftime("%Y-%m-%d") if filing.filing_date else "Unknown"
        
        lines = [
            f"# Infera Risk Analysis Report: {ticker}",
            "",
            f"**Report Generated:** {report_date}",
            f"**Filing Date:** {filing_date}",
            f"**Filing Type:** {filing.filing_type}",
            "",
            "---",
            "",
            "## Executive Summary",
            "",
        ]
        
        if summary:
            lines.append(summary.summary_text)
            lines.append("")
            lines.append(f"*Generated by {summary.model or 'GPT'} | Tokens: {summary.prompt_tokens or 0} prompt, {summary.completion_tokens or 0} completion*")
        else:
            lines.append("*No summary generated. Run pipeline with `--skip-summary=False` to generate.*")
        
        lines.extend([
            "",
            "---",
            "",
            "## Top Risk Factors (by severity score)",
            "",
        ])
        
        for i, (para, score) in enumerate(top_scored, 1):
            score_pct = score.score * 100
            lines.extend([
                f"### {i}. Risk Score: {score_pct:.1f}%",
                "",
                para.text,
                "",
            ])
        
        lines.extend([
            "---",
            "",
            "## Analysis Metadata",
            "",
            f"- **Ticker:** {ticker}",
            f"- **Total Paragraphs Analyzed:** {len(repo.get_paragraphs_by_section(db, risk_section.id))}",
            f"- **Section Word Count:** {risk_section.word_count or 'N/A'}",
            f"- **Source File:** {filing.source_file or 'N/A'}",
            "",
            "---",
            "",
            "*Report generated by Infera - AI-powered SEC Filing Analysis*",
        ])
        
        # Write report
        os.makedirs(output_dir, exist_ok=True)
        filename = f"{ticker}_{report_date}_risk_report.md"
        filepath = os.path.join(output_dir, filename)
        
        with open(filepath, "w") as f:
            f.write("\n".join(lines))
        
        logger.info(f"Report generated: {filepath}")
        return filepath
        
    finally:
        db.close()


def generate_report_from_pipeline_result(result: Dict[str, Any], output_dir: str = "reports") -> str:
    """
    Generate a report directly from pipeline result dict.
    This is faster as it doesn't need to re-query the database for most data.
    """
    ticker = result.get("ticker", "UNKNOWN")
    report_date = datetime.now().strftime("%Y-%m-%d")
    
    lines = [
        f"# Infera Risk Analysis Report: {ticker}",
        "",
        f"**Report Generated:** {report_date}",
        f"**Filing ID:** {result.get('filing_id', 'N/A')}",
        "",
        "---",
        "",
        "## Executive Summary",
        "",
    ]
    
    if "summary" in result:
        lines.append(result["summary"])
    else:
        lines.append("*No summary generated.*")
    
    lines.extend([
        "",
        "---",
        "",
        "## Top Risk Factors (by severity score)",
        "",
    ])
    
    if "top_scored" in result:
        for i, item in enumerate(result["top_scored"], 1):
            score_pct = item["score"] * 100
            lines.extend([
                f"### {i}. Risk Score: {score_pct:.1f}%",
                "",
                item["text"],
                "",
            ])
    else:
        lines.append("*No scored paragraphs available.*")
    
    lines.extend([
        "---",
        "",
        "## Analysis Metadata",
        "",
        f"- **Ticker:** {ticker}",
        f"- **Paragraphs Analyzed:** {result.get('paragraph_count', 'N/A')}",
        f"- **Section Word Count:** {result.get('word_count', 'N/A')}",
        "",
        "---",
        "",
        "*Report generated by Infera - AI-powered SEC Filing Analysis*",
    ])
    
    # Write report
    os.makedirs(output_dir, exist_ok=True)
    filename = f"{ticker}_{report_date}_risk_report.md"
    filepath = os.path.join(output_dir, filename)
    
    with open(filepath, "w") as f:
        f.write("\n".join(lines))
    
    logger.info(f"Report generated: {filepath}")
    return filepath


if __name__ == "__main__":
    import argparse
    
    parser = argparse.ArgumentParser(description="Generate risk analysis report")
    parser.add_argument("--filing-id", type=int, required=True, help="Filing ID to generate report for")
    parser.add_argument("--output-dir", default="reports", help="Output directory")
    args = parser.parse_args()
    
    path = generate_markdown_report(args.filing_id, args.output_dir)
    print(f"Report saved to: {path}")


