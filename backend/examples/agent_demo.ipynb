{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Infera Agent Demo\n",
        "\n",
        "This notebook demonstrates how to use Infera as a tool for AI agents.\n",
        "\n",
        "**What you'll learn:**\n",
        "1. Using the Python SDK to interact with Infera\n",
        "2. Understanding risk scores with explanations\n",
        "3. Semantic search across risk factors\n",
        "4. Integrating with LangGraph agents\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setup\n",
        "\n",
        "First, ensure the Infera API is running:\n",
        "```bash\n",
        "cd backend && uvicorn api.main:app --reload\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys\n",
        "sys.path.insert(0, '..')\n",
        "\n",
        "from sdk.infera_client import InferaClient\n",
        "\n",
        "# Initialize client\n",
        "client = InferaClient(base_url=\"http://localhost:8000\")\n",
        "\n",
        "# Check health\n",
        "health = client.health()\n",
        "print(f\"API Status: {health['status']}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. List Available Filings\n",
        "\n",
        "See what companies have been analyzed.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "filings = client.list_filings()\n",
        "\n",
        "print(f\"Found {len(filings)} filings:\\n\")\n",
        "for f in filings:\n",
        "    summary_status = \"✅\" if f.has_summary else \"❌\"\n",
        "    print(f\"  {f.ticker} ({f.filing_type}) - Summary: {summary_status}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Semantic Search\n",
        "\n",
        "Find risks related to a specific topic using natural language.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Search for cybersecurity risks\n",
        "results = client.search(\"cybersecurity data breach unauthorized access\", limit=5)\n",
        "\n",
        "print(f\"Found {len(results)} results:\\n\")\n",
        "for i, r in enumerate(results, 1):\n",
        "    print(f\"{i}. [{r.ticker}] Score: {r.score:.3f}\")\n",
        "    print(f\"   {r.text[:150]}...\")\n",
        "    print()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Explain a Risk Score\n",
        "\n",
        "Understand *why* a paragraph scored high or low using token attribution.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Pick a paragraph to explain\n",
        "if results:\n",
        "    paragraph_id = results[0].paragraph_id\n",
        "    \n",
        "    explanation = client.explain(paragraph_id, top_n=10)\n",
        "    \n",
        "    print(f\"Paragraph ID: {explanation.paragraph_id}\")\n",
        "    print(f\"Risk Score: {explanation.score:.3f}\")\n",
        "    print(f\"Confidence: {explanation.confidence:.1%}\")\n",
        "    print(f\"Category: {explanation.risk_category} ({explanation.category_confidence:.1%})\")\n",
        "    print()\n",
        "    print(\"Top contributing tokens:\")\n",
        "    for token in explanation.top_tokens[:5]:\n",
        "        print(f\"  • '{token.token}': +{token.contribution:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Get Raw Embeddings\n",
        "\n",
        "For advanced use cases, retrieve the actual embedding vectors.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if results:\n",
        "    paragraph = client.get_paragraph(results[0].paragraph_id, include_embedding=True)\n",
        "    \n",
        "    print(f\"Paragraph ID: {paragraph.paragraph_id}\")\n",
        "    print(f\"Score: {paragraph.score:.3f}\")\n",
        "    print(f\"Confidence: {paragraph.confidence:.1%}\")\n",
        "    \n",
        "    if paragraph.embedding:\n",
        "        print(f\"\\nEmbedding shape: {len(paragraph.embedding)} dimensions\")\n",
        "        print(f\"First 5 values: {paragraph.embedding[:5]}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## 5. LangGraph Integration\n",
        "\n",
        "Use Infera as a tool in a LangGraph agent.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import LangGraph tools\n",
        "from examples.langgraph_tool import (\n",
        "    analyze_risks,\n",
        "    explain_risk_score,\n",
        "    search_risks,\n",
        "    compare_companies,\n",
        "    get_filing_summary,\n",
        ")\n",
        "\n",
        "# Test search tool directly\n",
        "result = search_risks.invoke({\"query\": \"supply chain disruption\", \"limit\": 3})\n",
        "print(result)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create a full agent (requires OPENAI_API_KEY)\n",
        "import os\n",
        "\n",
        "if os.getenv(\"OPENAI_API_KEY\"):\n",
        "    from examples.langgraph_tool import create_infera_agent\n",
        "    from langchain_core.messages import HumanMessage\n",
        "    \n",
        "    agent = create_infera_agent()\n",
        "    \n",
        "    # Ask a question\n",
        "    response = agent.invoke({\n",
        "        \"messages\": [HumanMessage(content=\"What are the main cybersecurity risks disclosed by tech companies?\")]\n",
        "    })\n",
        "    \n",
        "    print(response[\"messages\"][-1].content)\n",
        "else:\n",
        "    print(\"Set OPENAI_API_KEY to run the agent example\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## 6. OpenAI Function Calling\n",
        "\n",
        "Use Infera with OpenAI's function calling API.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from examples.openai_functions import INFERA_FUNCTIONS, execute_function\n",
        "import json\n",
        "\n",
        "# Show available functions\n",
        "print(\"Available functions:\")\n",
        "for f in INFERA_FUNCTIONS:\n",
        "    print(f\"  • {f['function']['name']}\")\n",
        "\n",
        "# Execute a function directly\n",
        "result = execute_function(\n",
        "    \"search_risks\",\n",
        "    json.dumps({\"query\": \"regulatory compliance\", \"limit\": 3})\n",
        ")\n",
        "print(\"\\nSearch result:\")\n",
        "print(json.dumps(result, indent=2))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Summary\n",
        "\n",
        "This notebook demonstrated:\n",
        "\n",
        "1. **SDK Usage** - Clean Python interface to Infera API\n",
        "2. **Semantic Search** - Find risks by meaning, not keywords\n",
        "3. **Explainability** - Token-level attribution for every score\n",
        "4. **Confidence Scores** - Percentile-based uncertainty quantification\n",
        "5. **Raw Embeddings** - Access FinBERT vectors for custom analysis\n",
        "6. **LangGraph Tools** - Ready-to-use tools for LangGraph agents\n",
        "7. **OpenAI Functions** - Schema for Assistants API integration\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cleanup\n",
        "client.close()\n",
        "print(\"✅ Demo complete!\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
